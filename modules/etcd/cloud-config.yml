#cloud-config

---
coreos:

  flannel:
    interface: $private_ipv4
    etcd_cafile: /etc/kubernetes/ssl/ca.pem
    etcd_certfile: /etc/kubernetes/ssl/k8s-etcd.pem
    etcd_keyfile: /etc/kubernetes/ssl/k8s-etcd-key.pem
    etcd_endpoints: https://etcd.${ internal-tld }:2379

  locksmith:
    endpoint: https://etcd.${ internal-tld }:2379
    etcd_cafile: /etc/kubernetes/ssl/ca.pem
    etcd_certfile: /etc/kubernetes/ssl/k8s-etcd.pem
    etcd_keyfile: /etc/kubernetes/ssl/k8s-etcd-key.pem

  units:
    - name: etcd-member.service
      command: start
      drop-ins:
        - name: 01-wait-for-certs.conf
          content: |
            [Unit]
            After=create-certificates.service
            Requires=create-certificates.service
            ConditionFileNotEmpty=/etc/kubernetes/ssl/ca.pem
            ConditionFileNotEmpty=/etc/kubernetes/ssl/k8s-etcd.pem
            ConditionFileNotEmpty=/etc/kubernetes/ssl/k8s-etcd-key.pem

        - name: 10-environment.conf
          content: |
            [Service]
            Environment="ETCD_ADVERTISE_CLIENT_URLS=https://${ fqdn }:2379"
            Environment="ETCD_CERT_FILE=/etc/ssl/certs/k8s-etcd.pem"
            Environment="ETCD_CLIENT_CERT_AUTH=true"
            Environment="ETCD_DISCOVERY_SRV=${ internal-tld }"
            Environment="ETCD_INITIAL_ADVERTISE_PEER_URLS=https://${ fqdn }:2380"
            Environment="ETCD_INITIAL_CLUSTER_STATE=new"
            Environment="ETCD_INITIAL_CLUSTER_TOKEN=${ cluster-token }"
            Environment="ETCD_KEY_FILE=/etc/ssl/certs/k8s-etcd-key.pem"
            Environment="ETCD_LISTEN_CLIENT_URLS=https://0.0.0.0:2379"
            Environment="ETCD_LISTEN_PEER_URLS=https://0.0.0.0:2380"
            Environment="ETCD_NAME=${ hostname }"
            Environment="ETCD_PEER_CERT_FILE=/etc/ssl/certs/k8s-etcd.pem"
            Environment="ETCD_PEER_KEY_FILE=/etc/ssl/certs/k8s-etcd-key.pem"
            Environment="ETCD_PEER_TRUSTED_CA_FILE=/etc/ssl/certs/ca.pem"
            Environment="ETCD_SSL_DIR=/etc/kubernetes/ssl"
            Environment="ETCD_TRUSTED_CA_FILE=/etc/ssl/certs/ca.pem"

    - name: flanneld.service
      command: start
      drop-ins:
        - name: 50-network-config.conf
          content: |
            [Unit]
            Wants=create-certificates.service
            After=create-certificates.service
            [Service]
            EnvironmentFile=/etc/environment
            Environment="ETCD_SSL_DIR=/etc/kubernetes/ssl"
            ExecStartPre=-/usr/bin/etcdctl mk /coreos.com/network/config \
              '{ "Network": "${ pod-ip-range }", "Backend": { "Type": "vxlan" } }'
            Restart=always
            RestartSec=10

    - name: docker.service
      command: start
      drop-ins:
        - name: 40-flannel.conf
          content: |
            [Unit]
            After=flanneld.service
            Requires=flanneld.service
            [Service]
            Restart=always
            RestartSec=10

    - name: download-cfssl.service
      command: start
      content: |
        [Unit]
        After=network-online.target
        Requires=network-online.target
        Before=etcd-member.service
        Description=Download cfssl
        [Service]
        Type=oneshot
        RemainAfterExit=yes
        ExecStartPre=-/usr/bin/mkdir --parents /opt/bin
        ExecStartPre=/usr/bin/curl -L -o /opt/bin/cfssl https://pkg.cfssl.org/R1.2/cfssl_linux-amd64
        ExecStartPre=/usr/bin/curl -L -o /opt/bin/cfssljson https://pkg.cfssl.org/R1.2/cfssljson_linux-amd64
        ExecStart=/usr/bin/chmod +x /opt/bin/cfssl /opt/bin/cfssljson

    - name: create-certificates.service
      command: start
      content: |
        [Unit]
        After=download-cfssl.service
        Before=flannel.service
        ConditionFileIsExecutable=/opt/bin/cfssl
        Description=Get ssl artifacts from s3 bucket using IAM role and create local certificates
        Requires=download-cfssl.service
        [Service]
        ExecStartPre=-/usr/bin/mkdir -p /etc/kubernetes/ssl
        ExecStartPre=/opt/bin/fetch-from-s3 service-account-key.pem
        ExecStartPre=/opt/bin/fetch-from-s3 ca.pem
        ExecStart=/opt/bin/create-certificates
        RemainAfterExit=yes
        Type=oneshot

    - name: prefetch-rkt-hyperkube.service
      command: start
      content: |
        [Unit]
        After=network-online.target
        Requires=network-online.target
        Description=Prefetch rkt Hyperkube
        [Service]
        Type=oneshot
        RemainAfterExit=yes
        ExecStartPre=/usr/bin/rkt trust --trust-keys-from-https --prefix=quay.io/coreos/hyperkube
        ExecStart=/usr/bin/rkt fetch ${ hyperkube-image }:${ hyperkube-tag }

    - name: prefetch-docker-hyperkube.service
      command: start
      content: |
        [Unit]
        After=docker.service
        Requires=docker.service
        Description=Prefetch docker Hyperkube
        [Service]
        Type=oneshot
        RemainAfterExit=yes
        ExecStart=/usr/bin/docker pull ${ hyperkube }

    - name: kubelet.service
      command: start
      runtime: true
      content: |
        [Unit]
        ConditionFileNotEmpty=/etc/kubernetes/ssl/service-account-key.pem
        ConditionFileIsExecutable=/usr/lib/coreos/kubelet-wrapper
        After=flanneld.service
        After=prefetch-rkt-hyperkube.service
        After=prefetch-docker-hyperkube.service
        Requires=flanneld.service
        [Service]
        EnvironmentFile=-/etc/environment
        Environment="KUBELET_ACI=${ hyperkube-image }"
        Environment="KUBELET_VERSION=${ hyperkube-tag }"
        Environment="RKT_OPTS=\
          --volume dns,kind=host,source=/etc/resolv.conf \
          --mount volume=dns,target=/etc/resolv.conf \
          --volume rkt,kind=host,source=/opt/bin/host-rkt \
          --mount volume=rkt,target=/usr/bin/rkt \
          --volume var-lib-rkt,kind=host,source=/var/lib/rkt \
          --mount volume=var-lib-rkt,target=/var/lib/rkt \
          --volume stage,kind=host,source=/tmp \
          --mount volume=stage,target=/tmp \
          --volume var-log,kind=host,source=/var/log \
          --mount volume=var-log,target=/var/log"
        ExecStartPre=/usr/bin/mkdir -p /var/log/containers
        ExecStartPre=/usr/bin/mkdir -p /var/lib/kubelet
        ExecStartPre=/usr/bin/mount --bind /var/lib/kubelet /var/lib/kubelet
        ExecStartPre=/usr/bin/mount --make-shared /var/lib/kubelet
        ExecStart=/usr/lib/coreos/kubelet-wrapper \
          --allow-privileged=true \
          --api-servers=http://127.0.0.1:8080 \
          --cloud-provider=aws \
          --cluster-dns=${ dns-service-ip } \
          --cluster-domain=${ cluster-domain } \
          --kubeconfig=/etc/kubernetes/kubeconfig.yml \
          --pod-manifest-path=/etc/kubernetes/manifests \
          --node-labels node-role.kubernetes.io/master \
          --register-node=true \
          --register-with-taints node-role.kubernetes.io/master='':NoSchedule
        Restart=always
        RestartSec=5
        [Install]
        WantedBy=multi-user.target

  update:
    reboot-strategy: etcd-lock

write-files:

  - path: /etc/environment
    permissions: 0644
    content: |
      COREOS_PRIVATE_IPV4=$private_ipv4
      ETCD_CA_FILE=/etc/kubernetes/ssl/ca.pem
      ETCD_CERT_FILE=/etc/kubernetes/ssl/k8s-etcd.pem
      ETCD_KEY_FILE=/etc/kubernetes/ssl/k8s-etcd-key.pem
      ETCDCTL_CA_FILE=/etc/kubernetes/ssl/ca.pem
      ETCDCTL_CERT_FILE=/etc/kubernetes/ssl/k8s-etcd.pem
      ETCDCTL_KEY_FILE=/etc/kubernetes/ssl/k8s-etcd-key.pem
      ETCDCTL_ENDPOINT=https://${ fqdn }:2379

  - path: /opt/bin/host-rkt
    permissions: 0755
    owner: root:root
    content: |
      #!/bin/sh
      exec nsenter -m -u -i -n -p -t 1 -- /usr/bin/rkt "$@"

  - path: /etc/kubernetes/kubeconfig.yml
    content: |
      apiVersion: v1
      kind: Config
      clusters:
        - name: local
          cluster:
            server: http://127.0.0.1:8080
      users:
        - name: kubelet
      contexts:
        - name: kubelet-context
          context:
            cluster: local
            user: kubelet
      current-context: kubelet-context

  - path: /etc/kubernetes/manifests/kube-apiserver.yml
    content: |
      apiVersion: v1
      kind: Pod
      metadata:
        name: kube-apiserver
        namespace: kube-system
      spec:
        hostNetwork: true
        containers:
        - name: kube-apiserver
          image: ${ hyperkube }
          command:
          - /hyperkube
          - apiserver
          - --admission-control=NamespaceLifecycle,LimitRanger,ServiceAccount,DefaultStorageClass,ResourceQuota
          - --advertise-address=$private_ipv4
          - --apiserver-count=${ apiserver-count }
          - --allow-privileged=true
          - --anonymous-auth=false
          - --client-ca-file=/etc/kubernetes/ssl/ca.pem
          - --cloud-provider=aws
          - --enable-swagger-ui
          - --etcd-cafile=/etc/kubernetes/ssl/ca.pem
          - --etcd-certfile=/etc/kubernetes/ssl/k8s-etcd.pem
          - --etcd-keyfile=/etc/kubernetes/ssl/k8s-etcd-key.pem
          - --etcd-servers=https://etcd.${ internal-tld }:2379
          - --runtime-config=extensions/v1beta1=true,extensions/v1beta1/thirdpartyresources=true,apps/v1beta1=true
          - --secure-port=443
          - --service-account-key-file=/etc/kubernetes/ssl/service-account-key.pem
          - --service-account-lookup
          - --service-cluster-ip-range=${ service-cluster-ip-range }
          - --tls-cert-file=/etc/kubernetes/ssl/k8s-apiserver.pem
          - --tls-private-key-file=/etc/kubernetes/ssl/k8s-apiserver-key.pem
          - --v=2
          livenessProbe:
            httpGet:
              host: 127.0.0.1
              port: 8080
              path: /healthz
            initialDelaySeconds: 15
            timeoutSeconds: 15
          ports:
          - containerPort: 443
            hostPort: 443
            name: https
          - containerPort: 8080
            hostPort: 8080
            name: local
          volumeMounts:
          - mountPath: /etc/kubernetes/ssl
            name: ssl-certs-kubernetes
            readOnly: true
          - mountPath: /etc/ssl/certs
            name: ssl-certs-host
            readOnly: true
        volumes:
        - hostPath:
            path: /etc/kubernetes/ssl
          name: ssl-certs-kubernetes
        - hostPath:
            path: /usr/share/ca-certificates
          name: ssl-certs-host

  - path: /etc/kubernetes/manifests/kube-controller-manager.yml
    content: |
      apiVersion: v1
      kind: Pod
      metadata:
        name: kube-controller-manager
        namespace: kube-system
      spec:
        hostNetwork: true
        containers:
        - name: kube-controller-manager
          image: ${ hyperkube }
          command:
          - /hyperkube
          - controller-manager
          - --cloud-provider=aws
          - --leader-elect=true
          - --master=http://127.0.0.1:8080
          - --root-ca-file=/etc/kubernetes/ssl/ca.pem
          - --service-account-private-key-file=/etc/kubernetes/ssl/service-account-key.pem
          resources:
            requests:
              cpu: 200m
          livenessProbe:
            httpGet:
              host: 127.0.0.1
              path: /healthz
              port: 10252
            initialDelaySeconds: 15
            timeoutSeconds: 1
          volumeMounts:
          - mountPath: /etc/kubernetes/ssl
            name: ssl-certs-kubernetes
            readOnly: true
          - mountPath: /etc/ssl/certs
            name: ssl-certs-host
            readOnly: true
        volumes:
        - hostPath:
            path: /etc/kubernetes/ssl
          name: ssl-certs-kubernetes
        - hostPath:
            path: /usr/share/ca-certificates
          name: ssl-certs-host

  - path: /etc/kubernetes/manifests/kube-proxy.yml
    content: |
      apiVersion: v1
      kind: Pod
      metadata:
        name: kube-proxy
        namespace: kube-system
      spec:
        hostNetwork: true
        containers:
        - name: kube-proxy
          image: ${ hyperkube }
          command:
          - /hyperkube
          - proxy
          - --master=http://127.0.0.1:8080
          securityContext:
            privileged: true
          volumeMounts:
          - mountPath: /etc/ssl/certs
            name: ssl-certs-host
            readOnly: true
          - mountPath: /var/run/dbus
            name: dbus
            readOnly: false
        volumes:
        - hostPath:
            path: /usr/share/ca-certificates
          name: ssl-certs-host
        - hostPath:
            path: /var/run/dbus
          name: dbus

  - path: /etc/kubernetes/manifests/kube-scheduler.yml
    content: |
      apiVersion: v1
      kind: Pod
      metadata:
        name: kube-scheduler
        namespace: kube-system
      spec:
        hostNetwork: true
        containers:
        - name: kube-scheduler
          image: ${ hyperkube }
          command:
          - /hyperkube
          - scheduler
          - --leader-elect=true
          - --master=http://127.0.0.1:8080
          resources:
            requests:
              cpu: 100m
          livenessProbe:
            httpGet:
              host: 127.0.0.1
              path: /healthz
              port: 10251
            initialDelaySeconds: 15
            timeoutSeconds: 1

  - path: /etc/logrotate.d/docker-containers
    content: |
      /var/lib/docker/containers/*/*.log {
        rotate 7
        daily
        compress
        size=1M
        missingok
        delaycompress
        copytruncate
      }

  - path: /opt/bin/fetch-from-s3
    permissions: 0755
    owner: root:root
    content: |
      #!/bin/bash -e
      until /usr/bin/rkt run \
        --net=host \
        --trust-keys-from-https \
        --volume=dns,kind=host,source=/etc/resolv.conf,readOnly=true --mount volume=dns,target=/etc/resolv.conf \
        --volume=ssl,kind=host,source=/etc/kubernetes/ssl,readOnly=false --mount=volume=ssl,target=/etc/kubernetes/ssl \
        quay.io/coreos/awscli -- aws s3 cp s3://${ s3-bucket }/$1 /etc/kubernetes/ssl --region ${ region }
      do
        echo "retrying"
        sleep 5.2
      done
      echo "✓"

  - path: /opt/bin/wait-for-certs
    permissions: 0755
    owner: root:root
    content: |
      #!/bin/bash -e
      until ls /etc/kubernetes/ssl
      do
        echo "retrying"
        sleep 5.2
      done
      echo "✓"

  - path: /opt/bin/create-certificates
    permissions: 0755
    owner: root:root
    content: |
      #!/bin/bash -vex

      OUTDIR=/etc/kubernetes/ssl

      function error {
        echo "✗ Error on line $1"'!'
        exit 1
      }
      trap 'error $LINENO' ERR

      until printf "." && curl -d '{"label":"primary"}' http://pki.${ internal-tld }:8888/api/v1/cfssl/info &>/dev/null
      do sleep 5.2; done; echo "✓"

      DNS1="kubernetes"
      DNS2="kubernetes.default"
      DNS3="kubernetes.default.svc"
      DNS4="kubernetes.default.svc.cluster.local"
      DEFAULT_HOSTS="$DNS1,$DNS2,$DNS3,$DNS4,127.0.0.1"

      function csr {
        cat <<EOF
      {"CN":"$1","hosts":[""],"key":{"algo":"rsa","size":2048}}
      EOF
      }

      function generate {

        CN=$1
        PROFILE=$2
        HOSTS=$3

        echo "$(csr $CN)" \
          | /opt/bin/cfssl gencert \
            -remote=pki.${ internal-tld }:8888 \
            -profile=$PROFILE \
            -hostname="$HOSTS" - \
          | /opt/bin/cfssljson -bare $CN

        chmod 0644 $${CN}.pem $${CN}-key.pem

      }

      mkdir -p $OUTDIR && cd $OUTDIR

      generate k8s-apiserver client-server "$${DEFAULT_HOSTS},${ ip-k8s-service },master.${ internal-tld },${ external-elb }"
      generate k8s-etcd client-server "etcd.${ internal-tld },${ fqdn }"

  - path: /etc/kubernetes/cni/net.d/10-flannel.conf
    content: |
        {
            "name": "podnet",
            "type": "flannel",
            "delegate": {
                "isDefaultGateway": true
            }
        }
